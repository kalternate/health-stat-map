{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09009fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b617a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to seperate data into different files based on date\n",
    "# Return CSV files based on date\n",
    "# Takes as input: \n",
    "    # df: data frame of data to split. \n",
    "    # Indicator: Indicator for the dataset --> (string)\n",
    "    # YEAR: Column with the year to split on (I (Dylan) had it as YEAR) --> (string)\n",
    "def seperateFiles(df, Indicator: str, YEAR: str):\n",
    "    listDates = list(set((df[YEAR])))\n",
    "    for year in listDates:\n",
    "        # Gets new data frame with all the same date.\n",
    "        newDates_df = df[df[YEAR] == year]\n",
    "        # newDates_df\n",
    "        newDates_df.to_csv(f'{Indicator}_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef2d141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n~ Find common columns that have none to drop. # print(set(df['colName']))\\nDrop all of these columns:\\n'Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments'--> Dropped all values are {None}\\n\\n~ The column 'Date' only has this value I am guessing its the date the data was updated --> {'2024-12-10T17:44:48.22+01:00'}\\n    Maybe we could drop this column and store it as metadata somehow? DROPPED.\\n\\n~ SpatialDimType (this attribute includes Global and Regional. Not just country. What do we want to do with those?)\\nKEEP THESE AS IS...\\nSpatialDimType\\nCOUNTRY                 4705\\nREGION                   144\\nWORLDBANKINCOMEGROUP      96\\nGLOBAL                    24\\ndf['col1'].value_counts()\\n\\n~ TimeDimensionBegin and TimeDimensionEnd --> Seem to be just the time stamps at the start and end of the year. Should I drop those? \\nDrop TimeDimensionBegin, TimeDimensionEnd, and Date\\n\\n~ What is the difference between --> TimeDim and TimeDimensionValue ????? \\nThey are the same values, but...\\n    TimeDimensionValue --> string object\\n    TimeDim --> is a int64\\nKEEP TimeDim and Drop TimeDimensionValue\\n\\n~ Name of the file and indicator code should be the same... Drop IndicatorCode\\n\\n~ Change TimeDim --> Year. Drop TimeDimType\\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "~ Find common columns that have none to drop. # print(set(df['colName']))\n",
    "Drop all of these columns:\n",
    "'Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments'--> Dropped all values are {None}\n",
    "\n",
    "~ The column 'Date' only has this value I am guessing its the date the data was updated --> {'2024-12-10T17:44:48.22+01:00'}\n",
    "    Maybe we could drop this column and store it as metadata somehow? DROPPED.\n",
    "\n",
    "~ SpatialDimType (this attribute includes Global and Regional. Not just country. What do we want to do with those?)\n",
    "KEEP THESE AS IS...\n",
    "SpatialDimType\n",
    "COUNTRY                 4705\n",
    "REGION                   144\n",
    "WORLDBANKINCOMEGROUP      96\n",
    "GLOBAL                    24\n",
    "df['col1'].value_counts()\n",
    "\n",
    "~ TimeDimensionBegin and TimeDimensionEnd --> Seem to be just the time stamps at the start and end of the year. Should I drop those? \n",
    "Drop TimeDimensionBegin, TimeDimensionEnd, and Date\n",
    "\n",
    "~ What is the difference between --> TimeDim and TimeDimensionValue ????? \n",
    "They are the same values, but...\n",
    "    TimeDimensionValue --> string object\n",
    "    TimeDim --> is a int64\n",
    "KEEP TimeDim and Drop TimeDimensionValue\n",
    "\n",
    "~ Name of the file and indicator code should be the same... Drop IndicatorCode\n",
    "\n",
    "~ Change TimeDim --> Year. Drop TimeDimType\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea648d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDG_0000000017\n",
    "parquet_file = \"../DataCleaningCode/TB/MDG_0000000017.parquet\"\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "# Dropped all columns with {None}, \n",
    "# TimeDimensionValue (it was the string version of TimeDim), \n",
    "# TimeDimType (because it is just YEAR; Changed TimeDim --> Year), \n",
    "# IndicatorCode (because its the Name of the file),\n",
    "#  TimeDimensionBegin, TimeDimensionEnd, and Date (not valuable info)\n",
    "df.drop(columns=['Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments', \n",
    "                 'TimeDimensionValue', 'TimeDimType', 'IndicatorCode', 'TimeDimensionBegin', 'TimeDimensionEnd', 'Date'], inplace=True)\n",
    "\n",
    "# Renamed TimeDim --> Year\n",
    "df.rename({'TimeDim': 'YEAR'}, axis=1, inplace=True)\n",
    "\n",
    "# df\n",
    "# seperateFiles(df, './TB/TB_Files/MDG_0000000017', 'YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f45bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDG_0000000020\n",
    "parquet_file = \"../DataCleaningCode/TB/MDG_0000000020.parquet\"\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "# Dropped all columns with {None}, \n",
    "# TimeDimensionValue (it was the string version of TimeDim), \n",
    "# TimeDimType (because it is just YEAR; Changed TimeDim --> Year), \n",
    "# IndicatorCode (because its the Name of the file),\n",
    "#  TimeDimensionBegin, TimeDimensionEnd, and Date (not valuable info)\n",
    "df.drop(columns=['Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments', \n",
    "                 'TimeDimensionValue', 'TimeDimType', 'IndicatorCode', 'TimeDimensionBegin', 'TimeDimensionEnd', 'Date'], inplace=True)\n",
    "\n",
    "# Renamed TimeDim --> Year\n",
    "df.rename({'TimeDim': 'YEAR'}, axis=1, inplace=True)\n",
    "\n",
    "# df\n",
    "# seperateFiles(df, './TB/TB_Files/MDG_0000000020', 'YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d860c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TB_e_inc_num\n",
    "parquet_file = \"../DataCleaningCode/TB/TB_e_inc_num.parquet\"\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "# Dropped all columns with {None}, \n",
    "# TimeDimensionValue (it was the string version of TimeDim), \n",
    "# TimeDimType (because it is just YEAR; Changed TimeDim --> Year), \n",
    "# IndicatorCode (because its the Name of the file),\n",
    "#  TimeDimensionBegin, TimeDimensionEnd, and Date (not valuable info)\n",
    "df.drop(columns=['Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments', \n",
    "                 'TimeDimensionValue', 'TimeDimType', 'IndicatorCode', 'TimeDimensionBegin', 'TimeDimensionEnd', 'Date'], inplace=True)\n",
    "\n",
    "# Renamed TimeDim --> Year\n",
    "df.rename({'TimeDim': 'YEAR'}, axis=1, inplace=True)\n",
    "\n",
    "# df\n",
    "# seperateFiles(df, './TB/TB_Files/TB_e_inc_num', 'YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TB_e_mort_exc_tbhiv_num\n",
    "parquet_file = \"../DataCleaningCode/TB/TB_e_mort_exc_tbhiv_num.parquet\"\n",
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "# Dropped all columns with {None}, \n",
    "# TimeDimensionValue (it was the string version of TimeDim), \n",
    "# TimeDimType (because it is just YEAR; Changed TimeDim --> Year), \n",
    "# IndicatorCode (because its the Name of the file),\n",
    "#  TimeDimensionBegin, TimeDimensionEnd, and Date (not valuable info)\n",
    "df.drop(columns=['Dim1Type', 'Dim1', 'Dim2Type', 'Dim2', 'Dim3Type', 'Dim3', 'DataSourceDimType', 'DataSourceDim', 'Comments', \n",
    "                 'TimeDimensionValue', 'TimeDimType', 'IndicatorCode', 'TimeDimensionBegin', 'TimeDimensionEnd', 'Date'], inplace=True)\n",
    "\n",
    "# Renamed TimeDim --> Year\n",
    "df.rename({'TimeDim': 'YEAR'}, axis=1, inplace=True)\n",
    "\n",
    "# df\n",
    "# seperateFiles(df, './TB/TB_Files/TB_e_mort_exc_tbhiv_num', 'YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f37bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
